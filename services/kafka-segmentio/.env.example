# =============================================================================
# Kafka Service Environment Configuration
# =============================================================================
# Copy this file to .env and customize for your environment

# =============================================================================
# Kafka Broker Configuration
# =============================================================================

# Kafka broker addresses (comma-separated for multiple brokers)
KAFKA_BROKERS=127.0.0.1:9092

# Kafka protocol version
KAFKA_VERSION=2.8.0

# =============================================================================
# Kafka Topics Configuration
# =============================================================================

# Topic names
TOPIC_A=orders
TOPIC_B=payments

# Topic configuration
TOPIC_PARTITIONS=3
TOPIC_REPLICATION_FACTOR=1
TOPIC_RETENTION_MS=604800000

# Auto-create topics
AUTO_CREATE_TOPICS=true

# =============================================================================
# Producer Configuration
# =============================================================================

# Producer HTTP server
PRODUCER_HTTP_HOST=0.0.0.0
PRODUCER_HTTP_PORT=8082

# Producer settings
PRODUCER_BATCH_SIZE=16384
PRODUCER_LINGER_MS=5
PRODUCER_BUFFER_MEMORY=33554432
PRODUCER_ACKS=all
PRODUCER_RETRIES=3
PRODUCER_RETRY_BACKOFF_MS=100

# Compression
PRODUCER_COMPRESSION_TYPE=snappy

# =============================================================================
# Consumer Configuration
# =============================================================================

# Consumer group ID
GROUP_ID=demo-consumers

# Consumer settings
CONSUMER_SESSION_TIMEOUT=30s
CONSUMER_HEARTBEAT_INTERVAL=3s
CONSUMER_AUTO_OFFSET_RESET=earliest
CONSUMER_ENABLE_AUTO_COMMIT=true
CONSUMER_AUTO_COMMIT_INTERVAL=1s

# Consumer concurrency
CONSUMER_WORKERS=2

# =============================================================================
# Docker Kafka Configuration
# =============================================================================

# Kafka Docker settings
KAFKA_BROKER_ID=1
KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1

# Zookeeper Docker settings
ZOOKEEPER_CLIENT_PORT=2181
ZOOKEEPER_TICK_TIME=2000

# =============================================================================
# Security Configuration
# =============================================================================

# SASL authentication
SASL_ENABLED=false
SASL_MECHANISM=PLAIN
SASL_USERNAME=kafka
SASL_PASSWORD=kafka-secret

# SSL/TLS configuration
SSL_ENABLED=false
SSL_KEYSTORE_LOCATION=/path/to/kafka.keystore.jks
SSL_KEYSTORE_PASSWORD=keystore-password
SSL_TRUSTSTORE_LOCATION=/path/to/kafka.truststore.jks
SSL_TRUSTSTORE_PASSWORD=truststore-password

# =============================================================================
# Logging Configuration
# =============================================================================

# Log level (DEBUG, INFO, WARN, ERROR)
LOG_LEVEL=INFO

# Log format (json, text)
LOG_FORMAT=text

# Log output (stdout, stderr, file)
LOG_OUTPUT=stdout

# Log file paths
PRODUCER_LOG_FILE=logs/kafka-producer.log
CONSUMER_LOG_FILE=logs/kafka-consumer.log

# Enable Kafka client logging
KAFKA_LOG_ENABLED=false

# =============================================================================
# Health Check Configuration
# =============================================================================

# Health check timeout
HEALTH_CHECK_TIMEOUT=5s

# Kafka connection timeout
KAFKA_CONNECT_TIMEOUT=10s

# =============================================================================
# Monitoring Configuration
# =============================================================================

# Enable metrics collection
METRICS_ENABLED=true

# Metrics ports
PRODUCER_METRICS_PORT=9094
CONSUMER_METRICS_PORT=9095

# Enable tracing
TRACING_ENABLED=false

# Tracing endpoint
TRACING_ENDPOINT=http://localhost:14268/api/traces

# =============================================================================
# Message Configuration
# =============================================================================

# Message serialization format (json, avro, protobuf)
MESSAGE_FORMAT=json

# Message compression
MESSAGE_COMPRESSION=gzip

# Maximum message size
MAX_MESSAGE_SIZE=1048576

# =============================================================================
# Error Handling Configuration
# =============================================================================

# Dead letter topic
DEAD_LETTER_TOPIC=dead-letters
DEAD_LETTER_ENABLED=false

# Retry configuration
MAX_RETRIES=3
RETRY_BACKOFF_MS=1000

# Error handling strategy (skip, retry, dead_letter)
ERROR_STRATEGY=retry

# =============================================================================
# Development Configuration
# =============================================================================

# Development mode
DEV_MODE=true

# Enable debug logging
DEBUG=false

# Enable Kafka debug logging
KAFKA_DEBUG=false

# Mock mode (for testing without Kafka)
MOCK_MODE=false

# =============================================================================
# Performance Configuration
# =============================================================================

# Producer performance
PRODUCER_MAX_IN_FLIGHT_REQUESTS=5
PRODUCER_REQUEST_TIMEOUT_MS=30000

# Consumer performance
CONSUMER_FETCH_MIN_BYTES=1
CONSUMER_FETCH_MAX_WAIT_MS=500
CONSUMER_MAX_PARTITION_FETCH_BYTES=1048576

# Connection pool
MAX_CONNECTIONS=10
CONNECTION_IDLE_TIMEOUT=300s

# =============================================================================
# Schema Registry Configuration (if using Avro)
# =============================================================================

# Schema registry URL
SCHEMA_REGISTRY_URL=http://localhost:8081

# Schema registry authentication
SCHEMA_REGISTRY_AUTH_ENABLED=false
SCHEMA_REGISTRY_USERNAME=schema-user
SCHEMA_REGISTRY_PASSWORD=schema-password

# =============================================================================
# Production Configuration
# =============================================================================

# Production Kafka brokers
# PROD_KAFKA_BROKERS=kafka1:9092,kafka2:9092,kafka3:9092

# Production security
# PROD_SASL_ENABLED=true
# PROD_SSL_ENABLED=true

# Production performance
# PROD_PRODUCER_BATCH_SIZE=65536
# PROD_PRODUCER_LINGER_MS=10
# PROD_CONSUMER_WORKERS=10

# Production topics
# PROD_TOPIC_PARTITIONS=12
# PROD_TOPIC_REPLICATION_FACTOR=3

# =============================================================================
# Testing Configuration
# =============================================================================

# Test Kafka broker
TEST_KAFKA_BROKER=localhost:9092

# Test topics
TEST_TOPIC_PREFIX=test-

# Test timeout
TEST_TIMEOUT=30s

# =============================================================================
# Docker Compose Override
# =============================================================================

# Override Docker Compose project name
COMPOSE_PROJECT_NAME=apm-kafka

# Docker network
DOCKER_NETWORK=kafka-network

# =============================================================================
# Notes
# =============================================================================
# 1. Copy this file to .env and customize values
# 2. Start Kafka with: make docker-up
# 3. Create topics with: make kafka-topics-create
# 4. For production, use multiple brokers and proper replication
# 5. Enable security (SASL/SSL) for production deployments
# 6. Monitor Kafka metrics for performance optimization
# 7. Use schema registry for Avro message serialization
